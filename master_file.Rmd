---
  title: "Final Project: Twitter 2020 Democratic Canidate Sentiment"
author: "Forest Krueger and Victoria Owens"
date: "12/09/19"
output:
  pdf_document:
  toc: yes
keep_tex: true
html_document:
  code_folding: show
df_print: kable
highlight: textmate
theme: simplex
toc: yes
subtitle: R Markdown and LaTeX
bibliography: rmarkdown.bib
---
  
  ## 1. Introduction
  
  Why this project is relevant. Goal. Overview of project.

- candidates may need an idea of the trajectory of public opinion sooner than survey results can be returned
- plan to compare twitter data to survey data 
- prior efforts to do this
- similar efforts but not the same
- twitter data and surveys
- political twitter data
- sentiment analysis
-lower costs, faster results

## 2. Setup

Here we load the necessary libraries for preparation.

```{r, include=FALSE}
library(rtweet)
library(tidyverse)
library(ggmap)
library(dplyr)
library(tm)
library(tidytext)
library(SentimentAnalysis)
library(textdata)
```

In addition, the working directory will need to be set.

```{r,include=FALSE}
setwd("~/Desktop")
```

Finally, we use create_token() to prepare to collect the data from Twitter. 

```{r,include=FALSE}
create_token(
  app = "Twitter API String Tracker",
  consumer_key = "rCVjASAtmlConQfTd1R6XjOTx",
  consumer_secret = "ysYiFKXE2rdE2LOH2dp7Ow1tiiciNBR1Bz5uXMPKJghd1cLbkE",
  access_token = "843482256803020809-K20s6YXiVp6DEohoK0AUo11n3mLlPXI",
  access_secret = "zWaW1TE4OcUL8TcLqGNQxyo1ja68dmg2eIoU6lqQmOeMq"
)
```

## 3. Data
### Gathering

The data was collected with the code below. This is included only to demonstrate how the data was gathered; the dataset can be loaded in the code chunk following after.

```{r, eval=FALSE}
all_tweets <- search_tweets("@BernieSanders  OR @ewarren OR @KamalaHarris OR @PeteButtigieg OR @JoeBiden", n = 500000, verbose = TRUE, retryonratelimit = TRUE)
save(all_tweets,file="all_tweets.Rda")
```

The full dataset as it was collected from Twitter may be loaded below. This data can be downloaded here: https://drive.google.com/open?id=1vuRT8jAY0_Pds-mleHNS8nWsalRa2Z1R

```{r,include=FALSE}
load("all_tweets.Rda")
```

### Data Preparation

For our purposes, we are only interested in three columns of the dataset:
  
  text: text content of the tweet
location: Location of user according to the user's bio (not geotagging)
created_at: The time and date that the tweet was created

Below, we limit the data to include only these columns. In addition, the text column is cleaned in preparation for text analysis by removing unwanted characters. 

```{r,include=FALSE}
all_tweets_cut <-
  all_tweets %>%
  mutate(txt_clean = str_replace_all(text, "[^[:alnum:]]", " ")) %>%
  select(txt_clean, location, created_at)
```

We also take a quick look at the data to ensure it's what we expect before continuing forward. 

```{r}
head(all_tweets_cut, 20)
```

### Dataset Separation

We want to examine information at the state- and candidate-level. For this purpose, we will create 20 separate datasets with unique combinations of candidates and states. 

First, we create four datasets, one for each state of interest. Each dataset contains all of the records in which the location mentions a user's full state name ("Iowa") or abbreviation ("IA"). 

```{r}
IA_filter <- c(" IA", "Iowa")
NH_filter <- c(" NH", "New Hampshire")
SC_filter <- c(" SC", "South Carolina")
NV_filter <- c(" NV", "Nevada")


tweets_IA <- filter (all_tweets_cut, str_detect(location, paste(IA_filter, collapse="|")))

source(file="loop_1.R")

head(tweets_IA, 10)


```

Then, we create the full 20 datasets by separating each state dataset by candidate. A record corresponds to a candidate if the candidate's Twitter handle is mentioned in the tweet ("text" column). Tweets which mention more than one candidate will be included in each dataset.

```{r}
#Twitter handles
BS_filter <- c("BernieSanders")
EW_filter <- c("ewarren")
KH_filter <- c("KamalaHarris")
PB_filter <- c("PeteButtigieg")
JB_filter <- c("JoeBiden")
#Iowa
tweets_IA_BS <- filter(tweets_IA, str_detect(txt_clean, paste(BS_filter)))

source(file="loop_2.R")
```

```{r}
#Problem words specific to our data
remove <- c("t.co","joebiden","berniesanders","https","ewarren","petebuttigieg","bernie","joe","kamalaharris","elizabeth","warren","kamala","harris","biden","pete","buttigieg","sanders")
#General stop words
data("stop_words")
```

```{r,include=FALSE}
#BS IA Text prep

BS_IA_corpus <- Corpus(VectorSource(as.vector(tweets_IA_BS$txt_clean))) 
BS_IA_corpus<-tm_map(BS_IA_corpus, content_transformer(tolower))
BS_IA_corpus <- tm_map(BS_IA_corpus, stripWhitespace) 
BS_IA_corpus <- tm_map(BS_IA_corpus, removeWords, c(stopwords("english"),remove))
BS_IA_filter<-data.frame(text = sapply(BS_IA_corpus, as.character), stringsAsFactors = FALSE)

source(file="loop_3.R")
```

```{r}
BS_IA_sent <- analyzeSentiment(BS_IA_filter$text)
BS_IA_sent$Sentiment<-ifelse(BS_IA_sent$SentimentGI>0,"Pos",ifelse(BS_IA_sent$SentimentGI<0,"Neg","Neut"))



source(file="loop_4.R")

```

```{r}
print("Sanders Iowa Sentiment:")
print(table(BS_IA_sent$Sentiment))
```

```{r}
print("Warren Iowa Sentiment:")
print(table(EW_IA_sent$Sentiment))
```

```{r}
print("Harris Iowa Sentiment:")
print(table(KH_IA_sent$Sentiment))
```

```{r}
print("Buttigieg Iowa Sentiment:")
print(table(PB_IA_sent$Sentiment))
```

```{r}
print("Biden Iowa Sentiment:")
print(table(JB_IA_sent$Sentiment))
```

```{r}
print("Sanders New Hampshire Sentiment:")
print(table(BS_NH_sent$Sentiment))
```

```{r}
print("Warren New Hampshire Sentiment:")
print(table(EW_NH_sent$Sentiment))
```

```{r}
print("Harris New Hampshire Sentiment:")
print(table(KH_NH_sent$Sentiment))
```

```{r}
print("Buttigieg New Hampshire Sentiment:")
print(table(PB_NH_sent$Sentiment))
```

```{r}
print("Biden New Hampshire Sentiment:")
print(table(JB_NH_sent$Sentiment))
```

```{r}
print("Sanders South Carolina Sentiment:")
print(table(BS_SC_sent$Sentiment))
```

```{r}
print("Warren South Carolina Sentiment:")
print(table(EW_SC_sent$Sentiment))
```

```{r}
print("Harris South Carolina Sentiment:")
print(table(KH_SC_sent$Sentiment))
```

```{r}
print("Buttigieg South Carolina Sentiment:")
print(table(PB_SC_sent$Sentiment))
```

```{r}
print("Biden South Carolina Sentiment:")
print(table(JB_SC_sent$Sentiment))
```

```{r}
print("Sanders Nevada Sentiment:")
print(table(BS_NV_sent$Sentiment))
```

```{r}
print("Warren Nevada Sentiment:")
print(table(EW_NV_sent$Sentiment))
```

```{r}
print("Harris Nevada Sentiment:")
print(table(KH_NV_sent$Sentiment))
```

```{r}
print("Buttigieg Nevada Sentiment:")
print(table(PB_NV_sent$Sentiment))
```

```{r}
print("Biden Nevada Sentiment:")
print(table(JB_NV_sent$Sentiment))
```