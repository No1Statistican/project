---
title: "Final Project: Twitter 2020 Democratic Canidate Sentiment"
author: "Forest Krueger and Victoria Owens"
date: "12/09/19"
output:
  pdf_document:
    toc: yes
    keep_tex: true
  html_document:
    code_folding: show
    df_print: kable
    highlight: textmate
    theme: simplex
    toc: yes
subtitle: R Markdown and LaTeX
bibliography: rmarkdown.bib
---

## 1. Introduction

In recent years, Twitter has become an object of interest in public opinion measurement. Prior studies have successfully used Twitter data in lieu of survey data to predict presidential job approval (1), consumer sentiment (1), and the Irish General Election results (2) to name a few. However, Twitter's usefulness as a predictor of public opinion still remains an object of debate as it performs inconsistently. 

In this project, we intend to compare sentiment analysis on tweets with favorability polls on leading Democratic candidates Joe Biden, Bernie Sanders, Kamala Harris, Elizabeth Warren, and Pete Buttigieg in the early primary states of Iowa, Nevada, South Carolina, and New Hampshire. If tweets align with favorability polls, it may be feasible for candidates to use them as a source of information to understand more quickly and cheaply the state of public opinion than waiting for poll results. 

Our plan is to collect the tweets over several days in late November 2019, analyse the tweets to obtain a sentiment score for each candidate within each state, and compare the distributions of positive-to-negative tweets with their opinion poll counterparts. We hypothesize a similarity in distributions between the two. 

## 2. Setup

Here we load the necessary libraries for preparation.

```{r, include=FALSE}
library(rtweet)
library(tidyverse)
library(ggmap)
library(dplyr)
library(tm)
library(tidytext)
library(SentimentAnalysis)
library(textdata)
```

In addition, the working directory will need to be set.

```{r,include=FALSE}
setwd("~/Desktop")
```

Finally, we use create_token() to prepare to collect the data from Twitter. 

```{r,include=FALSE}
create_token(
  app = "Twitter API String Tracker",
  consumer_key = "rCVjASAtmlConQfTd1R6XjOTx",
  consumer_secret = "ysYiFKXE2rdE2LOH2dp7Ow1tiiciNBR1Bz5uXMPKJghd1cLbkE",
  access_token = "843482256803020809-K20s6YXiVp6DEohoK0AUo11n3mLlPXI",
  access_secret = "zWaW1TE4OcUL8TcLqGNQxyo1ja68dmg2eIoU6lqQmOeMq"
)
```

## 3. Data
### Gathering

The data was collected with the code below. This is included only to demonstrate how the data was gathered; the dataset can be loaded in the code chunk following after.

The initial data included 500,000 tweets covering in a 3-day span between November 23 and November 25 that mentioned candidates' twitter handles. 

```{r, eval=FALSE}
all_tweets <- search_tweets("@BernieSanders  OR @ewarren OR @KamalaHarris OR @PeteButtigieg OR @JoeBiden", n = 500000, verbose = TRUE, retryonratelimit = TRUE)

save(all_tweets,file="all_tweets.Rda")
```

The full dataset as it was collected from Twitter may be loaded below. This data can be downloaded here: https://drive.google.com/open?id=1vuRT8jAY0_Pds-mleHNS8nWsalRa2Z1R

```{r,include=FALSE}
load("all_tweets.Rda")
```

### Data Preparation

For our purposes, we are only interested in three columns of the dataset:

text: text content of the tweet
location: Location of user according to the user's bio (not geotagging)
created_at: The time and date that the tweet was created

Below, we limit the data to include only these columns. In addition, the text column is cleaned in preparation for text analysis by removing unwanted characters. 

```{r,include=FALSE}
all_tweets_cut <-
  all_tweets %>%
  mutate(txt_clean = str_replace_all(text, "[^[:alnum:]]", " ")) %>%
  select(txt_clean, location, created_at)
```

We also take a quick look at the data to ensure it's what we expect before continuing forward. 

```{r}
head(all_tweets_cut, 20)
```

### Dataset Separation

We want to examine information at the state- and candidate-level. For this purpose, we will create 20 separate datasets with each combination of candidates and states. 

First, we create four datasets, one for each state of interest. Each dataset contains all of the records in which the location mentions a user's full state name ("Iowa") or abbreviation ("IA"). 

```{r}
IA_filter <- c(" IA", "Iowa")
NH_filter <- c(" NH", "New Hampshire")
SC_filter <- c(" SC", "South Carolina")
NV_filter <- c(" NV", "Nevada")

tweets_IA <- filter (all_tweets_cut, str_detect(location, paste(IA_filter, collapse="|")))
tweets_NH <- filter (all_tweets_cut, str_detect(location, paste(NH_filter, collapse="|")))
tweets_SC <- filter (all_tweets_cut, str_detect(location, paste(SC_filter, collapse="|")))
tweets_NV <- filter (all_tweets_cut, str_detect(location, paste(NV_filter, collapse="|")))


head(tweets_IA, 20)
```

Then, we create the full 20 datasets by separating each state dataset by candidate. A record corresponds to a candidate if the candidate's Twitter handle is mentioned in the tweet ("text" column). Tweets which mention more than one candidate will be included in each dataset.

```{r}
#Twitter handles
BS_filter <- c("BernieSanders")
EW_filter <- c("ewarren")
KH_filter <- c("KamalaHarris")
PB_filter <- c("PeteButtigieg")
JB_filter <- c("JoeBiden")

#Iowa
tweets_IA_BS <- filter(tweets_IA, str_detect(txt_clean, paste(BS_filter)))
tweets_IA_EW <- filter(tweets_IA, str_detect(txt_clean, paste(EW_filter)))
tweets_IA_KH <- filter(tweets_IA, str_detect(txt_clean, paste(KH_filter)))
tweets_IA_PB <- filter(tweets_IA, str_detect(txt_clean, paste(PB_filter)))
tweets_IA_JB <- filter(tweets_IA, str_detect(txt_clean, paste(JB_filter)))

#New Hampshire
tweets_NH_BS <- filter(tweets_NH, str_detect(txt_clean, paste(BS_filter)))
tweets_NH_EW <- filter(tweets_NH, str_detect(txt_clean, paste(EW_filter)))
tweets_NH_KH <- filter(tweets_NH, str_detect(txt_clean, paste(KH_filter)))
tweets_NH_PB <- filter(tweets_NH, str_detect(txt_clean, paste(PB_filter)))
tweets_NH_JB <- filter(tweets_NH, str_detect(txt_clean, paste(JB_filter)))

#South Carolina
tweets_SC_BS <- filter(tweets_SC, str_detect(txt_clean, paste(BS_filter)))
tweets_SC_EW <- filter(tweets_SC, str_detect(txt_clean, paste(EW_filter)))
tweets_SC_KH <- filter(tweets_SC, str_detect(txt_clean, paste(KH_filter)))
tweets_SC_PB <- filter(tweets_SC, str_detect(txt_clean, paste(PB_filter)))
tweets_SC_JB <- filter(tweets_SC, str_detect(txt_clean, paste(JB_filter)))

#Nevada
tweets_NV_BS <- filter(tweets_NV, str_detect(txt_clean, paste(BS_filter)))
tweets_NV_EW <- filter(tweets_NV, str_detect(txt_clean, paste(EW_filter)))
tweets_NV_KH <- filter(tweets_NV, str_detect(txt_clean, paste(KH_filter)))
tweets_NV_PB <- filter(tweets_NV, str_detect(txt_clean, paste(PB_filter)))
tweets_NV_JB <- filter(tweets_NV, str_detect(txt_clean, paste(JB_filter)))
```

## 4. Sentiment Analysis

Before sentiment analysis can be performed, the text must be formatted properly. First, words to which no sentiment value will be assigned (common nouns in the tweets like "bernie" or common words like "and," as identified by the Harvard dictionary) will be removed from the text. 

```{r}
#Problem words specific to our data
remove <- c("t.co","joebiden","berniesanders","https","ewarren","petebuttigieg","bernie","joe","kamalaharris","elizabeth","warren","kamala","harris","biden","pete","buttigieg","sanders")

#General stop words
data("stop_words")

#BS IA Text prep
BS_IA_corpus <- 
  Corpus(VectorSource(as.vector(tweets_IA_BS$txt_clean))) %>%
  tm_map(content_transformer(tolower)) %>%
  tm_map(removeWords, c(stopwords("english"),remove)) 

BS_IA_filter <- data.frame(text = sapply(BS_IA_corpus, as.character), stringsAsFactors = FALSE)
BS_IA_filter
```

Now the data is formatted properly to begin the sentiment analysis. 

The scores of each word in each tweet will be added together to achieve a tweet-level score that is either positive, negative, or neutral (0). 

```{r}
#Sentiment analysis for Sanders in Iowa
BS_IA_sent <- analyzeSentiment(BS_IA_filter$text)
BS_IA_sent$Sentiment<-ifelse(BS_IA_sent$SentimentGI>0,"Pos",ifelse(BS_IA_sent$SentimentGI<0,"Neg","Neut"))

#Sentiment analysis for the rest of the states and candidates
source(file="loop_4.R")
```


## 5. Results

Below we include counts of tweets for each candidate/state by positive, negative, and neutral sentiment. *Didn't actually run these so correct the description if we need*

```{r}
print("Sanders Iowa Sentiment:")
print(table(BS_IA_sent$Sentiment))
```

```{r}
print("Warren Iowa Sentiment:")
print(table(EW_IA_sent$Sentiment))
```

```{r}
print("Harris Iowa Sentiment:")
print(table(KH_IA_sent$Sentiment))
```

```{r}
print("Buttigieg Iowa Sentiment:")
print(table(PB_IA_sent$Sentiment))
```

```{r}
print("Biden Iowa Sentiment:")
print(table(JB_IA_sent$Sentiment))
```

```{r}
print("Sanders New Hampshire Sentiment:")
print(table(BS_NH_sent$Sentiment))
```

```{r}
print("Warren New Hampshire Sentiment:")
print(table(EW_NH_sent$Sentiment))
```

```{r}
print("Harris New Hampshire Sentiment:")
print(table(KH_NH_sent$Sentiment))
```

```{r}
print("Buttigieg New Hampshire Sentiment:")
print(table(PB_NH_sent$Sentiment))
```

```{r}
print("Biden New Hampshire Sentiment:")
print(table(JB_NH_sent$Sentiment))
```

```{r}
print("Sanders South Carolina Sentiment:")
print(table(BS_SC_sent$Sentiment))
```

```{r}
print("Warren South Carolina Sentiment:")
print(table(EW_SC_sent$Sentiment))
```

```{r}
print("Harris South Carolina Sentiment:")
print(table(KH_SC_sent$Sentiment))
```

```{r}
print("Buttigieg South Carolina Sentiment:")
print(table(PB_SC_sent$Sentiment))
```

```{r}
print("Biden South Carolina Sentiment:")
print(table(JB_SC_sent$Sentiment))
```

```{r}
print("Sanders Nevada Sentiment:")
print(table(BS_NV_sent$Sentiment))
```

```{r}
print("Warren Nevada Sentiment:")
print(table(EW_NV_sent$Sentiment))
```

```{r}
print("Harris Nevada Sentiment:")
print(table(KH_NV_sent$Sentiment))
```

```{r}
print("Buttigieg Nevada Sentiment:")
print(table(PB_NV_sent$Sentiment))
```

```{r}
print("Biden Nevada Sentiment:")
print(table(JB_NV_sent$Sentiment))
```

To visualise these results more easily, we plot two separate bar charts for each candidate: one for Twitter, and one for polls, with a bar for each state, divided into positive and negative favorability. 

Below, we prepare the polls data for graphing. 

```{r}
pp <- read.csv("polls_prepped.csv")


pp <-
  pp %>%
  mutate(Percent = round(Percent*100))
pp
```

Now we graph the polls data for each candidate by state. 

```{r}
#Bernie Sanders
BS <- 
  pp %>%
  filter(Candidate == "BS") 

#text positioning
BS <- ddply(BS, .(State), transform, pos = cumsum(Percent) - (0.5 * Percent))

#create graph
plot_BS <- ggplot() + 
  geom_bar(aes(y = Percent, x = State, fill = Type), data = BS, stat="identity") +
  scale_fill_manual(values=c("black", "blue")) + 
  geom_text(data=BS, aes(x = State, y = pos, label = paste0(Percent,"%")), size=4, color="white") + 
  ggtitle("Poll-Based Opinions of Bernie Sanders by State")

plot_BS


#Kamala Harris
KH <- 
  pp %>%
  filter(Candidate == "KH") 
  
#text positioning
KH <- ddply(KH, .(State), transform, pos = cumsum(Percent) - (0.5 * Percent))

#create graph
plot_KH <- ggplot() + 
  geom_bar(aes(y = Percent, x = State, fill = Type), data = KH,stat="identity") + 
  scale_fill_manual(values=c("black", "blue")) + 
  geom_text(data=KH, aes(x = State, y = pos, label = paste0(Percent,"%")), size=4, color="white") + 
  ggtitle("Poll-Based Opinions of Kamala Harris by State")

plot_KH


#Elizabeth Warren
EW <- 
  pp %>%
  filter(Candidate == "EW") 
  
#text positioning
EW <- ddply(EW, .(State), transform, pos = cumsum(Percent) - (0.5 * Percent))

#create graph
plot_EW <- ggplot() + 
  geom_bar(aes(y = Percent, x = State, fill = Type), data = EW, stat="identity") + 
  scale_fill_manual(values=c("black", "blue")) + 
  geom_text(data=EW, aes(x = State, y = pos, label = paste0(Percent,"%")), size=4, color="white") + 
  ggtitle("Poll-Based Opinions of Elizabeth Warren by State")

plot_EW


#Pete Buttigieg
PB <- 
  pp %>%
  filter(Candidate == "PB") 
  
#text positioning
PB <- ddply(PB, .(State), transform, pos = cumsum(Percent) - (0.5 * Percent))

#create graph
plot_PB <- ggplot() + 
  geom_bar(aes(y = Percent, x = State, fill = Type), data = PB, stat="identity") + 
  scale_fill_manual(values=c("black", "blue")) + 
  geom_text(data=PB, aes(x = State, y = pos, label = paste0(Percent,"%")), size=4, color="white") + 
  ggtitle("Poll-Based Opinions of Pete Buttigieg by State")

plot_PB


#Joe Biden
JB <- 
  pp %>%
  filter(Candidate == "JB") 
  
#text positioning
JB <- ddply(JB, .(State), transform, pos = cumsum(Percent) - (0.5 * Percent))

#create graph
plot_JB <- ggplot() + 
  geom_bar(aes(y = Percent, x = State, fill = Type), data = JB, stat="identity") + 
  scale_fill_manual(values=c("black", "blue")) + 
  geom_text(data=JB, aes(x = State, y = pos, label = paste0(Percent,"%")), size=4, color="white") + 
  ggtitle("Poll-Based Opinions of Joe Biden by State")

plot_JB

```

Similarly, below we load the data for graphing the Twitter sentiments. 

```{r}
sp <- read.csv("sentiments_prepped.csv")
sp <-
  sp %>%
  mutate(Percent = round(Percent*100))
sp
```

Now we graph the Twitter sentiments for each candidate by state.

```{r}
#Bernie Sanders
BS <- 
  sp %>%
  filter(Candidate == "BS") 
  
#text positioning
BS <- ddply(BS, .(State), transform, pos = cumsum(Percent) - (0.5 * Percent))

#create graph
plot_BS <- ggplot() + 
  geom_bar(aes(y = Percent, x = State, fill = Type), data = BS, stat="identity") + 
  scale_fill_manual(values=c("black", "blue")) + 
  geom_text(data=BS, aes(x = State, y = pos, label = paste0(Percent,"%")), size=4, color="white") + 
  ggtitle("Twitter Sentiments of Bernie Sanders by State")

plot_BS


#Kamala Harris
KH <- 
  sp %>%
  filter(Candidate == "KH") 
  
#text positioning
KH <- ddply(KH, .(State), transform, pos = cumsum(Percent) - (0.5 * Percent))

#create graph
plot_KH <- ggplot() + 
  geom_bar(aes(y = Percent, x = State, fill = Type), data = KH, stat="identity") + 
  scale_fill_manual(values=c("black", "blue")) + 
  geom_text(data=KH, aes(x = State, y = pos, label = paste0(Percent,"%")), size=4, color="white") + 
  ggtitle("Twitter Sentiments of Kamala Harris by State")

plot_KH


#Elizabeth Warren
EW <- 
  sp %>%
  filter(Candidate == "EW") 
  
#text positioning
EW <- ddply(EW, .(State), transform, pos = cumsum(Percent) - (0.5 * Percent))

#create graph
plot_EW <- ggplot() + 
  geom_bar(aes(y = Percent, x = State, fill = Type), data = EW, stat="identity") + 
  scale_fill_manual(values=c("black", "blue")) + 
  geom_text(data=EW, aes(x = State, y = pos, label = paste0(Percent,"%")), size=4, color="white") + 
  ggtitle("Twitter Sentiments of Elizabeth Warren by State")

plot_EW


#Pete Buttigieg
PB <- 
  sp %>%
  filter(Candidate == "PB") 
  
#text positioning
PB <- ddply(PB, .(State), transform, pos = cumsum(Percent) - (0.5 * Percent))

#create graph
plot_PB <- ggplot() + 
  geom_bar(aes(y = Percent, x = State, fill = Type), data = PB, stat="identity") + 
  scale_fill_manual(values=c("black", "blue")) + 
  geom_text(data=PB, aes(x = State, y = pos, label = paste0(Percent,"%")), size=4, color="white") + 
  ggtitle("Twitter Sentiments of Pete Buttigieg by State")

plot_PB


#Joe Biden
JB <- 
  sp %>%
  filter(Candidate == "JB") 
  
#text positioning
JB <- ddply(JB, .(State), transform, pos = cumsum(Percent) - (0.5 * Percent))

#create graph
plot_JB <- ggplot() + 
  geom_bar(aes(y = Percent, x = State, fill = Type), data = JB, stat="identity") + 
  scale_fill_manual(values=c("black", "blue")) + 
  geom_text(data=JB, aes(x = State, y = pos, label = paste0(Percent,"%")), size=4, color="white") + 
  ggtitle("Twitter Sentiments of Joe Biden by State")

plot_JB
```

In addition, we run a regression in an attempt to see whether the Twitter sentiments correlate with poll outcomes and could be used for prediction. Below, the data is prepared for this purpose, deriving sentiment and poll favorability ratios for comparison. 

```{r}
df_polls<-read.csv("polls.csv")
df_twitter<-read.csv("twitter.csv")
```
```{r}
df_polls$p_ratio<-df_polls$Positive/df_polls$Negative
df_twitter$t_ratio<-df_twitter$Positive/df_twitter$Negative
drops <- c("Positive", "Negative")
df_polls<-df_polls[ , !(names(df_polls) %in% drops)]
df_twitter<-df_twitter[ , !(names(df_twitter) %in% drops)]
pred <- merge(x = df_polls, y = df_twitter, by=c("State","Candidate"))
```

Using regression and not supervised machine learning. Not nearly enough data. As you can see there is not good predictive power trying to directly predict the canidate sentiments, looking at something like the trends over longer periods would be more useful

```{r}
regress <- lm(p_ratio ~ t_ratio + State + Candidate, data=pred)
summary(regress)
```

## 6. Discussion

Twitter results were not consistenly close to poll results for any candidate or in any state. In several cases (for example, Elizabeth Warren in South Carolina), Tweets were drastically more negative than poll results indicated. Visual inspection of the graphs is confirmed by the regression, which did not show that twitter results were useful for predicting poll results. Hence, we would not advocate attempting predictions using the methods above. However, there are many aspects of predictions using social media data that we did not explore here, such as attempting weighting the twitter data by user characteristics; accounting for retweets or likes; and measuring sentiment with different methods. *Can we attribute these ideas to someone?*

In fact, the limitatations of this study are numerous, and using social media data for this type of application is still quite experimental. For this project, limitations divide mainly into general problems with political Tweets in general or problems with comparison to polls.   

Analysing political Tweets as done in this project is challenging for multiple reasons. One problem with our approach is that we did not limit to unique users; one user could be included in the dataset multiple times, expressing the same sentiment repeatedly. It is likely there are many organizational Twitter accounts in the data that are likely to often tweet for or against a specific candidate. In fact, it has been shown that the top 10% of users produce 80% of Twitter content (4). In addition, attempting to assign a sentiment value to a political tweet is a complicated process if only using individual word values. Political comments are often sarcastic, which our approach is not sophisticated enough to account for. 

When comparing to the polls, the demographics of Twitter users does not match that of the general population; they are known to be younger, more educated, wealthier, and more likely to identify as Democratic (4). Additionally, for many candidate-state combinations, sample sizes were lacking; the smallest size was only 75 tweets, while the largest only 889. Also, although the data was collected in a period close to when polls were conducted, there was not a perfect overlap. Tweets were collected from November 23, 2019 - November 25, 2019, while the most recently available polls were conducted at various points in each state between September 22 and November 9. Clearly, polls that reflect opinions at a different time period are not easily comparable. 

However, it may be possible that Tweets are indicitive of the trajectory of public opinion, rather than its momentary state. Comparing the current polls to those immediately previous, Biden and Warren both fell, while Buttigieg rose and Sanders was constant. Interestingly, the Twitter sentiments compared to polls showed lower ratings for Biden and Warren, higher ratings for Buttigieg, and similar ratings for Sanders. This suggests there may be some correlation between the state of Twitter opinions and the shifting of public opnion. If true, this information would be useful for candidates to know whether they are likely to be falling or rising before the next poll results become available, particularly after debates. Data over a longer period of time to correspond to multiple poll results are needed to verify this hypothesis. This is the avenue of research we believe most promising from this point. 

#We need a bibliography
#Also need to add the polls here
# (1) https://arxiv.org/pdf/1608.02024.pdf
# (2) https://www.aclweb.org/anthology/W11-3702.pdf
# (3) https://www.aaai.org/ocs/index.php/ICWSM/ICWSM11/paper/view/2816/3234
# (4) https://www.pewresearch.org/internet/2019/04/24/sizing-up-twitter-users/



#make sure lang=en (english Tweet)
#make sure correct geolocation #location
#some will say City, ST , other will say State, USA
#https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/intro-to-tweet-json
